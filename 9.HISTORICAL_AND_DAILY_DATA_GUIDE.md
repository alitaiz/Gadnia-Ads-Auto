# Hướng Dẫn: Tải Dữ liệu Lịch sử & Tự động hóa Hàng ngày

## Giới thiệu

Chúc mừng bạn đã thiết lập thành công các script để lấy dữ liệu từ Amazon! Giờ là lúc đưa chúng vào hoạt động. Hướng dẫn này sẽ chỉ cho bạn 3 bước cốt lõi:

1.  **Chuẩn bị Database:** Chạy các file migration SQL để tạo tất cả các bảng cần thiết và **cấp quyền truy cập** cho ứng dụng.
2.  **Tải Dữ liệu Lịch sử (Backfilling):** Chạy các script một lần để lấy dữ liệu từ 60-90 ngày qua, cung cấp ngữ cảnh cho các phân tích của bạn.
3.  **Tự động hóa Hàng ngày:** Thiết lập một "cron job" trên server để tự động lấy dữ liệu của ngày hôm qua, mỗi ngày, giữ cho database của bạn luôn mới.

---

## Yêu cầu

-   Bạn đã đăng nhập vào VPS của mình qua SSH.
-   Toàn bộ code dự án đã có trên VPS.
-   File `backend/.env` đã được cấu hình đầy đủ và chính xác.

---

## Phần 1: Chuẩn bị Cơ sở dữ liệu (Chạy Migrations)

Trước khi có thể lưu dữ liệu, chúng ta cần tạo các bảng tương ứng trong PostgreSQL và cấp quyền cho user của ứng dụng.

> **QUAN TRỌNG:** Các file migration đã được nâng cấp để **an toàn khi chạy lại**. Nếu bạn gặp lỗi liên quan đến bảng hoặc cột không tồn tại (ví dụ: `column "sales" does not exist`), chỉ cần chạy lại các lệnh `\i` dưới đây. Hệ thống sẽ tự động thêm các cột còn thiếu mà không xóa dữ liệu hiện có.

1.  **Đăng nhập vào PostgreSQL:**
    -   Sử dụng lệnh sau để kết nối trực tiếp vào database của bạn với quyền quản trị.
        ```bash
        sudo -u postgres psql -d amazon_data_gadnia
        ```
    -   Dấu nhắc lệnh sẽ đổi thành `amazon_data_gadnia=#`.

2.  **Chạy các file Migration cần thiết:**
    -   Sử dụng lệnh `\i` của `psql` để thực thi một file. Hãy thay `/var/www/Gadnia-Ads-Auto` bằng đường dẫn **CHÍNH XÁC** đến thư mục dự án của bạn.
    -   Chạy lần lượt các lệnh sau theo đúng thứ tự:
        ```sql
        -- Bảng báo cáo Sponsored Products Search Term
        \i /var/www/Gadnia-Ads-Auto/backend/migrations/003_add_sp_search_term_report_table.sql.txt

        -- Bảng báo cáo Sales & Traffic
        \i /var/www/Gadnia-Ads-Auto/backend/migrations/004_add_sales_and_traffic_tables.sql.txt

        -- Bảng hàng đợi yêu cầu báo cáo (quan trọng cho quy trình mới)
        \i /var/www/Gadnia-Ads-Auto/backend/migrations/005_add_report_requests_table.sql.txt

        -- Bảng báo cáo Sponsored Brands Search Term
        \i /var/www/Gadnia-Ads-Auto/backend/migrations/008_add_sb_search_term_report_table.sql.txt
        
        -- Bảng báo cáo Sponsored Display Targeting
        \i /var/www/Gadnia-Ads-Auto/backend/migrations/009_add_sd_targeting_report_table.sql.txt
        ```
    -   Bạn sẽ thấy các thông báo như `CREATE TABLE`, `ALTER TABLE`, và `GRANT`, cho biết lệnh đã thành công.

3.  **Thoát khỏi psql:**
    -   Gõ `\q` và nhấn Enter để quay lại terminal bình thường.

**Database của bạn giờ đã sẵn sàng để nhận dữ liệu!**

---

## Phần 2: Tải Dữ liệu Lịch sử (Backfilling)

Bây giờ chúng ta sẽ chạy các script để lấp đầy các bảng vừa tạo với dữ liệu từ 60 ngày qua. Việc tải dữ liệu lịch sử có thể mất nhiều thời gian, vì vậy bạn cần chạy chúng dưới dạng tiến trình nền (background process) để chúng không bị tắt khi bạn đóng cửa sổ dòng lệnh.

**Quan trọng:** Hãy chạy các lệnh này bên trong thư mục gốc của dự án của bạn (ví dụ: `/var/www/Gadnia-Ads-Auto`).

### 2.1. Di chuyển đến thư mục dự án
```bash
cd /var/www/Gadnia-Ads-Auto
```

### 2.2. Tải Báo cáo Search Term & Targeting (SP, SB, SD) - Quy trình Hai Giai đoạn

Để tải dữ liệu lịch sử số lượng lớn một cách hiệu quả, chúng ta sử dụng quy trình hai giai đoạn đã được mô tả trong [Hướng dẫn 10](10.HIGH_VOLUME_DATA_FETCHING_GUIDE.md).

#### Giai đoạn 1: Gửi Yêu cầu Hàng loạt

Script này sẽ gửi yêu cầu tạo báo cáo cho mỗi ngày trong khoảng thời gian bạn chỉ định và lưu vào hàng đợi, nó chạy rất nhanh.

1.  **Bắt đầu một phiên `screen` để chạy ngầm:**
    ```bash
    screen -S backfill-requests
    ```
2.  Bên trong phiên `screen`, chạy các lệnh sau để yêu cầu báo cáo cho 60 ngày qua (thay đổi ngày tháng nếu cần):
    ```bash
    # Yêu cầu báo cáo Sponsored Products
    npm run request:sp-search-terms -- 2025-09-23 2025-09-23

    # Yêu cầu báo cáo Sponsored Brands
    npm run request:sb-search-terms -- 2025-09-19 2025-09-19

    # Yêu cầu báo cáo Sponsored Display
    npm run request:sd-targeting -- 2025-09-23 2025-09-23
    ```
3.  **Ngắt kết nối (Detach):** Nhấn tổ hợp phím **`Ctrl + A`**, sau đó nhấn phím **`d`**. Bạn sẽ quay lại terminal chính.
4.  **CHỜ ĐỢI:** Bạn cần **chờ ít nhất 1-2 tiếng** để Amazon xử lý và tạo các báo cáo này.

#### Giai đoạn 2: Xử lý các Báo cáo đang chờ

Sau khi chờ đủ lâu, script này sẽ kiểm tra hàng đợi, tìm các báo cáo đã hoàn thành, tải chúng về và lưu dữ liệu.

1.  **Chạy script xử lý:**
    ```bash
    npm run process:pending-reports
    ```
2.  Bạn có thể chạy lại lệnh này nhiều lần. Nó sẽ chỉ xử lý các báo cáo đã hoàn thành và bỏ qua những báo cáo vẫn đang được tạo. Để tự động hóa hoàn toàn, hãy xem Phần 3.

### 2.3. Tải Báo cáo Sales & Traffic

Báo cáo này vẫn sử dụng quy trình một giai đoạn.

1.  **Bắt đầu một phiên `screen` khác:**
    ```bash
    screen -S sales-traffic-backfill
    ```
2.  Bên trong phiên, chạy lệnh với khoảng thời gian bạn muốn (ví dụ 60 ngày):
    ```bash
    npm run fetch:sales-traffic -- 2024-07-15 2024-09-12
    ```
3.  **Ngắt kết nối (Detach):** Nhấn **`Ctrl + A`**, sau đó **`d`**.

---

## Phần 3: Tự động hóa Lấy Dữ liệu Hàng ngày với Cron

Đây là bước thiết lập một lần và hệ thống sẽ tự chạy mãi mãi. Chúng ta sẽ tạo một "cron job", một tác vụ được lập lịch trên Linux, để tự động chạy các script mỗi ngày. Dữ liệu quảng cáo thường có độ trễ, vì vậy lấy dữ liệu của 2 ngày trước sẽ đảm bảo dữ liệu đầy đủ và chính xác hơn.

1.  **Mở trình chỉnh sửa Crontab:**
    ```bash
    crontab -e
    ```
    -   Nếu đây là lần đầu tiên, bạn có thể được yêu cầu chọn một trình soạn thảo. Hãy chọn `nano`.

2.  **Thêm các dòng Cron Job:**
    -   Di chuyển con trỏ xuống cuối file và dán nội dung sau vào.
    -   **CỰC KỲ QUAN TRỌNG:** Hãy thay đổi `/var/www/Gadnia-Ads-Auto` thành đường dẫn **CHÍNH XÁC** đến thư mục dự án của bạn và đảm bảo dòng `PATH` là chính xác.

    ### Lưu ý quan trọng về Môi trường Cron (CRITICAL NOTE ON CRON ENVIRONMENT)
    `cron` chạy trong một môi trường rất tối giản. Để nó có thể tìm thấy các lệnh như `npm`, bạn **PHẢI** thêm một dòng `PATH` ở đầu file crontab.
    
    1.  **Tìm đường dẫn `npm` của bạn:** Chạy lệnh `which npm` trong terminal.
    2.  **Sao chép thư mục chứa nó:** Ví dụ: `/home/youruser/.nvm/versions/node/v20.11.0/bin`.
    3.  **Thêm vào crontab:** Thêm dòng `PATH=/your/copied/path:/usr/bin:/bin` vào đầu file crontab của bạn, như trong ví dụ dưới đây.

    ```cron
    # ---------------- CRONTAB EXAMPLE ----------------
    
    # Cung cấp đường dẫn đến Node.js/npm để cron có thể tìm thấy chúng.
    # THAY THẾ đường dẫn này bằng kết quả từ lệnh `which npm` của bạn.
    PATH=/root/.nvm/versions/node/v22.17.1/bin:/usr/bin:/bin
    
    # Đặt múi giờ cho tất cả các cron job là UTC-7 (America/Phoenix).
    # Việc này đảm bảo các lệnh `date` hoạt động nhất quán.
    TZ=America/Phoenix

    # Giai đoạn 1: Yêu cầu báo cáo hàng ngày lúc 1:00 AM cho dữ liệu của ngày hôm qua
    0 1 * * * cd /var/www/Gadnia-Ads-Auto && npm run request:sp-search-terms -- $(date -d "1 day ago" +\%Y-\%m-\%d) $(date -d "1 day ago" +\%Y-\%m-\%d) >> /var/www/Gadnia-Ads-Auto/logs/cron_sp_search_term_request.log 2>&1
    5 1 * * * cd /var/www/Gadnia-Ads-Auto && npm run request:sb-search-terms -- $(date -d "1 day ago" +\%Y-\%m-\%d) $(date -d "1 day ago" +\%Y-\%m-\%d) >> /var/www/Gadnia-Ads-Auto/logs/cron_sb_search_term_request.log 2>&1
    8 1 * * * cd /var/www/Gadnia-Ads-Auto && npm run request:sd-targeting -- $(date -d "1 day ago" +\%Y-\%m-\%d) $(date -d "1 day ago" +\%Y-\%m-\%d) >> /var/www/Gadnia-Ads-Auto/logs/cron_sd_targeting_request.log 2>&1
    
    # Tự động lấy báo cáo Sales & Traffic hàng ngày lúc 1:10 AM cho dữ liệu của ngày hôm qua
    10 1 * * * cd /var/www/Gadnia-Ads-Auto && npm run fetch:sales-traffic -- $(date -d "2 day ago" +\%Y-\%m-\%d) $(date -d "2 day ago" +\%Y-\%m-\%d) >> /var/www/Gadnia-Ads-Auto/logs/cron_sales_traffic.log 2>&1
    
    # Giai đoạn 2: Tự động xử lý các báo cáo đang chờ trong hàng đợi mỗi 45 phút
    */45 * * * * cd /var/www/Gadnia-Ads-Auto && npm run process:pending-reports >> /var/www/Gadnia-Ads-Auto/logs/cron_process_pending_reports.log 2>&1

    # ---------------- END CRONTAB EXAMPLE ----------------
    ```

3.  **Lưu và Thoát:**
    -   Nhấn `Ctrl + X`, sau đó `Y`, và `Enter`.
    -   Bạn sẽ thấy thông báo `crontab: installing new crontab`.

4.  **Tạo thư mục Logs:**
    -   Cron job sẽ ghi log vào thư mục `logs`, chúng ta cần tạo nó.
    -   Từ thư mục gốc của dự án, chạy lệnh:
        ```bash
        mkdir -p logs
        ```

## Hoàn tất!

Hệ thống của bạn giờ đã được thiết lập hoàn chỉnh! Nó không chỉ chứa dữ liệu lịch sử mà còn sẽ tự động cập nhật dữ liệu mới mỗi ngày. Ngày mai, bạn có thể kiểm tra các file trong thư mục `logs` để xác nhận rằng các cron job đã chạy thành công.

---

## Xử lý sự cố (Troubleshooting)

### Lỗi: `permission denied for table ...` hoặc `column "..." does not exist`

- **Nguyên nhân:** Lỗi này xảy ra khi schema database của bạn không khớp với phiên bản code hiện tại (ví dụ: thiếu bảng hoặc cột).
- **Giải pháp:**
    1. Quay lại **Phần 1** của hướng dẫn này.
    2. **Chạy lại tất cả các lệnh `\i`** trong `psql`. Các script migration đã được thiết kế để an toàn khi chạy lại. Chúng sẽ tự động tạo các bảng hoặc thêm các cột còn thiếu mà không gây lỗi hoặc mất dữ liệu.

### Lỗi: Cron job không chạy

- **Nguyên nhân 1: Sai `PATH`** - Đây là nguyên nhân phổ biến nhất. `cron` không tìm thấy lệnh `npm`.
- **Giải pháp 1:** Thực hiện theo **"Lưu ý quan trọng về Môi trường Cron"** ở trên. Đảm bảo dòng `PATH=...` là chính xác.

- **Cách kiểm tra:** Xem các file log trong thư mục `logs` và log hệ thống (`grep CRON /var/log/syslog`) để tìm manh mối.